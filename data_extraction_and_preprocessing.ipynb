{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebc39e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from collections import OrderedDict\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31ab8b5",
   "metadata": {},
   "source": [
    "# load raw data: MIMIC-IV v2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c70e04",
   "metadata": {},
   "source": [
    "## 1. Cohort extraction: patients with admission history and didn't die in hospital. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4cc8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = '/data/chao/mimic/physionet.org/files/mimiciv/2.0/hosp' ## Replace with your local path for mimiciv-2.0 data\n",
    "\n",
    "# load patients, make patient dictionary.\n",
    "patients = pd.read_csv(folder_name + '/patients.csv')\n",
    "patients_dict = {}\n",
    "for row in patients.values:\n",
    "    patients_dict[row[0]] = [row[1], row[2], row[3], row[4], row[5]]  # gender, anchor_age, anchor_year, anchor_year_group, dod\n",
    "\n",
    "# load admission\n",
    "admissions = pd.read_csv(folder_name + '/admissions.csv')\n",
    "patients_anchor_age_not_last_v_y = {}\n",
    "tmp = admissions.groupby(['subject_id'])\n",
    "for key, item in tmp:\n",
    "    group_df = tmp.get_group(key)\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    discharge_time_list = [datetime.strptime(str_time, \"%Y-%m-%d %H:%M:%S\") for str_time in list(group_df['dischtime'])]\n",
    "    last_discharge_timestr = sorted(discharge_time_list, key=lambda t: t, reverse=True)[0].strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    last_admission_row_id = list(group_df['dischtime'] == last_discharge_timestr).index(1)\n",
    "    if key in patients_dict.keys():\n",
    "        patients_dict[key] = patients_dict[key] + [group_df.iloc[last_admission_row_id]['race'], group_df.iloc[last_admission_row_id]['hadm_id'], group_df.iloc[last_admission_row_id]['admittime'], group_df.iloc[last_admission_row_id]['dischtime'], group_df.iloc[last_admission_row_id]['deathtime'], group_df.iloc[last_admission_row_id]['admission_type'], group_df.iloc[last_admission_row_id]['insurance'], group_df.iloc[last_admission_row_id]['admission_location'], group_df.iloc[last_admission_row_id]['discharge_location']]\n",
    "    \n",
    "    if patients_dict[key][2] != int(patients_dict[key][7][:4]):\n",
    "        patients_anchor_age_not_last_v_y[key] = [patients_dict[key][1], patients_dict[key][2], patients_dict[key][7]]\n",
    "\n",
    "patients_dict_w_admission = {}\n",
    "patients_dict_w_admission_n_die_inhosp = {}\n",
    "one_y_outcome = {}\n",
    "die_count = 0\n",
    "for key, ele in patients_dict.items():\n",
    "    if len(ele) > 5:\n",
    "        patients_dict_w_admission[key] = ele\n",
    "        if ele[9] != ele[9]: # patients not die in hospital\n",
    "            patients_dict_w_admission_n_die_inhosp[key] = ele\n",
    "            if ele[4] == ele[4]:\n",
    "                one_y_outcome[key] = 1  # die in one year after last hospital stay\n",
    "                die_count += 1\n",
    "            else:\n",
    "                one_y_outcome[key] = 0  # not die in one year after last hospital stay\n",
    "\n",
    "print(\"Num of patients in total: %d\" % len(patients_dict))        \n",
    "print(\"Num of patients with admissions: %d\" % len(patients_dict_w_admission))\n",
    "print(\"Num of patients with admissions and not die in hospital: %d\" % len(patients_dict_w_admission_n_die_inhosp))\n",
    "print(\"    among which, %d (%.2f) patients died in one year after their last admission.\" % (die_count, die_count/len(patients_dict_w_admission_n_die_inhosp))) \n",
    "\n",
    "\n",
    "np.save('/data/chao/syn_mimic/preprocessing/patients_dict_w_admission.npy', patients_dict_w_admission)\n",
    "np.save('/data/chao/syn_mimic/preprocessing/patients_anchor_age_not_last_v_y.npy', patients_anchor_age_not_last_v_y)\n",
    "np.save('/data/chao/syn_mimic/preprocessing/patients_dict_w_admission_n_die_inhosp.npy', patients_dict_w_admission_n_die_inhosp)\n",
    "np.save('/data/chao/syn_mimic/preprocessing/one_y_outcome.npy', one_y_outcome)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b675ef96",
   "metadata": {},
   "source": [
    "## 2. Diagnosis extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05371dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load diagnoses\n",
    "diagnoses = pd.read_csv(folder_name + '/diagnoses_icd.csv')\n",
    "diagnoses_pt_df = pd.DataFrame()\n",
    "tmp = diagnoses.groupby(['subject_id'])\n",
    "\n",
    "for key, item in tmp:\n",
    "    if key in patients_dict_w_admission_n_die_inhosp.keys():\n",
    "        group_df = tmp.get_group(key)\n",
    "        group_df = group_df.reset_index(drop=True)\n",
    "        diagnoses_pt_df = diagnoses_pt_df.append(group_df, ignore_index=True)\n",
    "        \n",
    "diagnoses_pt_df.to_csv(folder_name + '/diagnoses_selected_cohort.csv', index=False)\n",
    "\n",
    "# diagnoses_pt_df = pd.read_csv(folder_name + '/diagnoses_selected_cohort.csv')\n",
    "\n",
    "patient_diagnosis_dict = {}\n",
    "patients_w_icd_9_10 = []\n",
    "temp = diagnoses_pt_df.groupby(['subject_id', 'icd_version'])\n",
    "for key, item in temp:\n",
    "    if key[0] not in patient_diagnosis_dict.keys():\n",
    "        patient_diagnosis_dict[key[0]] = {'icd9':[], 'icd10':[]}\n",
    "    if key[1] == 9:\n",
    "        patient_diagnosis_dict[key[0]]['icd9'] = list(set(item['icd_code']))\n",
    "    else:\n",
    "        patient_diagnosis_dict[key[0]]['icd10'] = list(set(item['icd_code']))\n",
    "    \n",
    "    if len(patient_diagnosis_dict[key[0]]['icd9']) > 0 and len(patient_diagnosis_dict[key[0]]['icd10']) > 0:\n",
    "        patients_w_icd_9_10.append(key[0])\n",
    "\n",
    "np.save('/data/chao/syn_mimic/preprocessing/patient_diagnosis_dict.npy', patient_diagnosis_dict)\n",
    "np.save('/data/chao/syn_mimic/preprocessing/patients_w_icd_diag_9_10.npy', patients_w_icd_9_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e986b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(patients_w_icd_9_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4426fd",
   "metadata": {},
   "source": [
    "## 3. Procedure extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b177fcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load procedure hcpcs\n",
    "procedures_hcpcs = pd.read_csv(folder_name + '/hcpcsevents.csv')\n",
    "procedures_hcpcs_pt_df = pd.DataFrame()\n",
    "tmp = procedures_hcpcs.groupby(['subject_id'])\n",
    "for key, item in tmp:\n",
    "    if key in patients_dict_w_admission_n_die_inhosp.keys():\n",
    "        group_df = tmp.get_group(key)\n",
    "        group_df = group_df.reset_index(drop=True)\n",
    "        procedures_hcpcs_pt_df = procedures_hcpcs_pt_df.append(group_df, ignore_index=True)\n",
    "        \n",
    "procedures_hcpcs_pt_df.to_csv(folder_name + '/procedures_hcpcs_selected_cohort.csv', index=False)\n",
    "\n",
    "patient_procedures_hcpcs_dict = {}\n",
    "temp = procedures_hcpcs_pt_df.groupby(['subject_id'])\n",
    "for key, item in temp:\n",
    "    hcpcs_list = list(item['hcpcs_cd'])\n",
    "    cpt_list = []\n",
    "    for code in hcpcs_list:\n",
    "        if not any(c.isalpha() for c in code):\n",
    "            cpt_list.append(code)\n",
    "    patient_procedures_hcpcs_dict[key] = list(set(cpt_list))\n",
    "    \n",
    "np.save('/data/chao/syn_mimic/preprocessing/patient_procedures_hcpcs_dict.npy', patient_procedures_hcpcs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4bd2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load procedure icd\n",
    "procedures_icd = pd.read_csv(folder_name + '/procedures_icd.csv')\n",
    "procedures_icd_pt_df = pd.DataFrame()\n",
    "tmp = procedures_icd.groupby(['subject_id'])\n",
    "for key, item in tmp:\n",
    "    if key in patients_dict_w_admission_n_die_inhosp.keys():\n",
    "        group_df = tmp.get_group(key)\n",
    "        group_df = group_df.reset_index(drop=True)\n",
    "        procedures_icd_pt_df = procedures_icd_pt_df.append(group_df, ignore_index=True)\n",
    "        \n",
    "procedures_icd_pt_df.to_csv(folder_name + '/procedures_icd_selected_cohort.csv', index=False)\n",
    "\n",
    "patient_procedures_icd_dict = {}\n",
    "patients_w_icd_9_10 = []\n",
    "temp = procedures_icd_pt_df.groupby(['subject_id', 'icd_version'])\n",
    "for key, item in temp:\n",
    "    if key[0] not in patient_procedures_icd_dict.keys():\n",
    "        patient_procedures_icd_dict[key[0]] = {'icd9':[], 'icd10':[]}\n",
    "    if key[1] == 9:\n",
    "        patient_procedures_icd_dict[key[0]]['icd9'] = list(set(item['icd_code']))\n",
    "    else:\n",
    "        patient_procedures_icd_dict[key[0]]['icd10'] = list(set(item['icd_code']))\n",
    "    \n",
    "    if len(patient_procedures_icd_dict[key[0]]['icd9']) > 0 and len(patient_procedures_icd_dict[key[0]]['icd10']) > 0:\n",
    "        patients_w_icd_9_10.append(key[0])\n",
    "\n",
    "np.save('/data/chao/syn_mimic/preprocessing/patient_procedures_icd_dict.npy', patient_procedures_icd_dict)\n",
    "np.save('/data/chao/syn_mimic/preprocessing/patients_w_icd_proc_9_10.npy', patients_w_icd_9_10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c651573c",
   "metadata": {},
   "source": [
    "## 4. Prescription extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8024b85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prescription (ndc codes)\n",
    "prescriptions = pd.read_csv(folder_name + '/prescriptions.csv', dtype={\"ndc\":np.str})\n",
    "prescriptions = prescriptions[[\"subject_id\", \"hadm_id\", \"ndc\"]]\n",
    "prescriptions_pt_df = pd.DataFrame()\n",
    "tmp = prescriptions.groupby(['subject_id'])\n",
    "\n",
    "count = 0\n",
    "for key, item in tmp:\n",
    "    if key in patients_dict_w_admission_n_die_inhosp.keys():\n",
    "        group_df = tmp.get_group(key)\n",
    "        group_df = group_df.reset_index(drop=True)\n",
    "        prescriptions_pt_df = prescriptions_pt_df.append(group_df, ignore_index=True)\n",
    "        \n",
    "    count += 1\n",
    "    if count % 5000 == 1:\n",
    "        print(count)\n",
    "        \n",
    "prescriptions_pt_df.to_csv(folder_name + '/prescriptions_selected_cohort.csv', index=False)\n",
    "\n",
    "patient_prescriptions_dict = {}\n",
    "temp = prescriptions_pt_df.groupby(['subject_id'])\n",
    "for key, item in temp:\n",
    "    candidate_list = list(set(item['ndc']))\n",
    "    if '0' in candidate_list:\n",
    "        candidate_list.remove('0')\n",
    "    patient_prescriptions_dict[key] = candidate_list\n",
    "\n",
    "np.save('/data/chao/syn_mimic/preprocessing/patient_prescriptions_dict.npy', patient_prescriptions_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8a4496",
   "metadata": {},
   "source": [
    "## 5. Other measure extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ae575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load BMI blood pressure (diastolic/systolic)\n",
    "measures = pd.read_csv(folder_name + '/omr.csv')\n",
    "measures_pt_df = pd.DataFrame()\n",
    "tmp = measures.groupby(['subject_id'])\n",
    "\n",
    "patient_bmi_bp = {}\n",
    "for key, item in tmp:\n",
    "    if key in patients_dict_w_admission_n_die_inhosp.keys():\n",
    "        group_df = tmp.get_group(key)\n",
    "        group_df = group_df.reset_index(drop=True)\n",
    "        group_df = group_df.sort_values(by='chartdate',ascending=False)\n",
    "        cat_list = list(group_df['result_name'])\n",
    "        if 'BMI (kg/m2)' in cat_list:\n",
    "            bmi_index = cat_list.index('BMI (kg/m2)')\n",
    "            bmi = np.float(group_df.iloc[bmi_index]['result_value'])\n",
    "        else:\n",
    "            bmi = np.nan\n",
    "            \n",
    "        if 'Blood Pressure' in cat_list:\n",
    "            bp_index = cat_list.index('Blood Pressure')\n",
    "            bp_str = group_df.iloc[bp_index]['result_value'].split('/')\n",
    "            dias_bp = np.float(bp_str[1])\n",
    "            syst_bp = np.float(bp_str[0])\n",
    "            if dias_bp <= 0 and syst_bp <=0:\n",
    "                dias_bp = np.nan\n",
    "                syst_bp = np.nan\n",
    "        else:\n",
    "            dias_bp = np.nan\n",
    "            syst_bp = np.nan\n",
    "            \n",
    "        patient_bmi_bp[key] = [bmi, dias_bp, syst_bp]\n",
    "        \n",
    "np.save('/data/chao/syn_mimic/preprocessing/patient_bmi_bp_dict.npy', patient_bmi_bp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b583bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_bmi_bp_dict = np.load('/data/chao/syn_mimic/preprocessing/patient_bmi_bp_dict.npy', allow_pickle=True).item()\n",
    "len(patient_bmi_bp_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff6ff52",
   "metadata": {},
   "source": [
    "# Build patient by concept matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b78ce46",
   "metadata": {},
   "source": [
    "## 1.a Diagnosis (map to Phecode)  --> the tutorial uses this mapping instead of 1.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a177ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load icd to phemap mapping\n",
    "phecode_icd9_map = pd.read_csv('/data/chao/syn_mimic/preprocessing/mapping_tables/phecode_icd9_map_unrolled.csv', dtype={\"phecode\":np.str})\n",
    "phecode_icd9_map_dict = {}\n",
    "for row in phecode_icd9_map.values:\n",
    "    if str(row[1]) != 'nan':\n",
    "        phecode_icd9_map_dict[row[0].replace(\".\", \"\")] = row[1]\n",
    "\n",
    "phecode_icd10_map = pd.read_csv('/data/chao/syn_mimic/preprocessing/mapping_tables/Phecode_map_v1_2_icd10_beta.csv', dtype={\"PHECODE\":np.str})\n",
    "phecode_icd10_map_dict = {}\n",
    "for row in phecode_icd10_map.values:\n",
    "    if str(row[1]) != 'nan':\n",
    "        phecode_icd10_map_dict[row[0].replace(\".\", \"\")] = row[1]\n",
    "\n",
    "\n",
    "patient_diagnosis_dict = np.load('/data/chao/syn_mimic/preprocessing/patient_diagnosis_dict.npy', allow_pickle=True).item()\n",
    "patient_diagnosis_final_dict = {}\n",
    "missed_icd9_code = []\n",
    "missed_icd10_code = []\n",
    "for key, code_list in patient_diagnosis_dict.items():\n",
    "    icd9_list = code_list['icd9']\n",
    "    icd10_list = code_list['icd10']\n",
    "    phecodes_for_icd9_list = []\n",
    "    phecodes_for_icd10_list = []\n",
    "    \n",
    "    for code in icd9_list:\n",
    "        if code in phecode_icd9_map_dict.keys():\n",
    "            phecodes_for_icd9_list.append(phecode_icd9_map_dict[code])\n",
    "        else:\n",
    "            if len(code) > 3:\n",
    "                if code[:len(code)-1] in phecode_icd9_map_dict.keys():\n",
    "                    phecodes_for_icd9_list.append(phecode_icd9_map_dict[code[:len(code)-1]])\n",
    "                elif code[:len(code)-2] in phecode_icd9_map_dict.keys():\n",
    "                    phecodes_for_icd9_list.append(phecode_icd9_map_dict[code[:len(code)-2]])\n",
    "                else:\n",
    "                    missed_icd9_code.append(code)\n",
    "                \n",
    "    for code in icd10_list:\n",
    "        if code in phecode_icd10_map_dict.keys():\n",
    "            phecodes_for_icd10_list.append(phecode_icd10_map_dict[code])\n",
    "        else:\n",
    "            if len(code)>4:\n",
    "                if code[:len(code)-1] in phecode_icd10_map_dict.keys():\n",
    "                    phecodes_for_icd10_list.append(phecode_icd10_map_dict[code[:len(code)-1]])\n",
    "                elif code[:len(code)-2] in phecode_icd10_map_dict.keys():\n",
    "                    phecodes_for_icd10_list.append(phecode_icd10_map_dict[code[:len(code)-2]])\n",
    "                elif code[:len(code)-3] in phecode_icd10_map_dict.keys():\n",
    "                    phecodes_for_icd10_list.append(phecode_icd10_map_dict[code[:len(code)-3]])\n",
    "                else:\n",
    "                    missed_icd10_code.append(code)\n",
    "            \n",
    "    patient_diagnosis_final_dict[key] = list(set(phecodes_for_icd9_list + phecodes_for_icd10_list))\n",
    "    \n",
    "np.save('/data/chao/syn_mimic/preprocessing/patient_phecode_diagnosis_final_dict.npy', patient_diagnosis_final_dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1a91df",
   "metadata": {},
   "source": [
    "## 1.b Diagnosis (map to icd9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b161a393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load icd10 to icd9 mapping\n",
    "icd10_icd9_map = pd.read_csv('/data/chao/syn_mimic/preprocessing/mapping_tables/icd10cmtoicd9gem.csv')\n",
    "icd10_icd9_map_dict = {}\n",
    "for row in icd10_icd9_map.values:\n",
    "    if str(row[1]) != 'nan':\n",
    "        icd10_icd9_map_dict[row[0]] = row[1]\n",
    "\n",
    "patient_diagnosis_dict = np.load('./patient_diagnosis_dict.npy', allow_pickle=True).item()\n",
    "patient_diagnosis_final_dict = {}\n",
    "missed_icd10_code = []\n",
    "for key, code_list in patient_diagnosis_dict.items():\n",
    "    icd9_list = code_list['icd9']\n",
    "    icd10_list = code_list['icd10']\n",
    "    mapped_icd10_list = []\n",
    "                    \n",
    "    for code in icd10_list:\n",
    "        if code in icd10_icd9_map_dict.keys():\n",
    "            mapped_icd10_list.append(icd10_icd9_map_dict[code])\n",
    "        else:\n",
    "            if len(code)>4:\n",
    "                if code[:len(code)-1] in icd10_icd9_map_dict.keys():\n",
    "                    mapped_icd10_list.append(icd10_icd9_map_dict[code[:len(code)-1]])\n",
    "                elif code[:len(code)-2] in icd10_icd9_map_dict.keys():\n",
    "                    mapped_icd10_list.append(icd10_icd9_map_dict[code[:len(code)-2]])\n",
    "                elif code[:len(code)-3] in icd10_icd9_map_dict.keys():\n",
    "                    mapped_icd10_list.append(icd10_icd9_map_dict[code[:len(code)-3]])\n",
    "                else:\n",
    "                    missed_icd10_code.append(code)\n",
    "            \n",
    "    patient_diagnosis_final_dict[key] = list(set(icd9_list + mapped_icd10_list))\n",
    "    \n",
    "    \n",
    "np.save('/data/chao/syn_mimic/preprocessing/patient_ICD_diagnosis_final_dict.npy', patient_diagnosis_final_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744748ff",
   "metadata": {},
   "source": [
    "## 2. Procedure (cpt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6131bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_procedures_hcpcs_final_dict = np.load('/data/chao/syn_mimic/preprocessing/patient_procedures_hcpcs_dict.npy', allow_pickle=True).item()\n",
    "patient_procedures_hcpcs_final_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2af01d",
   "metadata": {},
   "source": [
    "## 3. Prescription (ndc-->rxcui-->ingradient rxcui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d392501",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_prescriptions_dict = np.load('/data/chao/syn_mimic/preprocessing/patient_prescriptions_dict.npy', allow_pickle=True).item()\n",
    "patient_prescriptions_dict\n",
    "\n",
    "patient_prescriptions_rxcui_final_dict = {}\n",
    "patient_prescriptions_ingr_rxcui_final_dict = {}\n",
    "\n",
    "count = 0\n",
    "for key, item in patient_prescriptions_dict.items():\n",
    "    rxcui_list = []\n",
    "    ingr_list = []\n",
    "    for ndc_code in item:\n",
    "        response = requests.get(f'https://rxnav.nlm.nih.gov/REST/relatedndc.json?relation=product&ndc={ndc_code}')\n",
    "        content = response.json()\n",
    "        if len(content)>0:\n",
    "            rxcui = content['ndcInfoList']['ndcInfo'][0]['rxcui']\n",
    "            rxcui_list.append(rxcui)\n",
    "            response_ing = requests.get(f'https://rxnav.nlm.nih.gov/REST/rxcui/{rxcui}/historystatus.json?caller=RxNav').json()\n",
    "            drug_type = response_ing['rxcuiStatusHistory']['attributes']['tty']\n",
    "            if response_ing['rxcuiStatusHistory']['derivedConcepts'] is not None:\n",
    "                num_ingredient = len(response_ing['rxcuiStatusHistory']['derivedConcepts']['ingredientConcept'])\n",
    "                for i in range(0,num_ingredient):\n",
    "                    ingredient = response_ing['rxcuiStatusHistory']['derivedConcepts']['ingredientConcept'][i]['ingredientRxcui']\n",
    "                    ingr_list.append(ingredient)\n",
    "    \n",
    "    patient_prescriptions_rxcui_final_dict[key] = list(set(rxcui_list))\n",
    "    patient_prescriptions_ingr_rxcui_final_dict[key] = list(set(ingr_list))\n",
    "    count += 1\n",
    "    if count % 5000 == 1:\n",
    "        print(count, flush=True)\n",
    "    \n",
    "    \n",
    "np.save('/data/chao/syn_mimic/preprocessing/patient_prescriptions_rxcui_final_dict.npy', patient_prescriptions_rxcui_final_dict)\n",
    "np.save('/data/chao/syn_mimic/preprocessing/patient_prescriptions_ingr_rxcui_final_dict.npy', patient_prescriptions_ingr_rxcui_final_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5f139f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "patient_prescriptions_dict = np.load('/data/chao/syn_mimic/preprocessing/patient_prescriptions_dict.npy', allow_pickle=True).item()\n",
    "\n",
    "distinct_ndc_dict = {}\n",
    "for key, item in patient_prescriptions_dict.items():\n",
    "    for ndc_code in item:\n",
    "        if ndc_code not in distinct_ndc_dict.keys():\n",
    "            distinct_ndc_dict[ndc_code] = 1\n",
    "        else:\n",
    "            distinct_ndc_dict[ndc_code] = distinct_ndc_dict[ndc_code] + 1\n",
    "\n",
    "ndc_rxcui_mapping = {}\n",
    "ndc_rxcui_ingr_mapping = {}\n",
    "\n",
    "count = 0\n",
    "for ndc in distinct_ndc_dict.keys():\n",
    "    response = requests.get(f'https://rxnav.nlm.nih.gov/REST/relatedndc.json?relation=product&ndc={ndc}')\n",
    "    content = response.json()\n",
    "    if len(content)>0:\n",
    "        rxcui = content['ndcInfoList']['ndcInfo'][0]['rxcui']\n",
    "        ndc_rxcui_mapping[ndc] = rxcui\n",
    "        response_ing = requests.get(f'https://rxnav.nlm.nih.gov/REST/rxcui/{rxcui}/historystatus.json?caller=RxNav').json()\n",
    "        drug_type = response_ing['rxcuiStatusHistory']['attributes']['tty']\n",
    "        if response_ing['rxcuiStatusHistory']['derivedConcepts'] is not None:\n",
    "            ingr_list = []\n",
    "            num_ingredient = len(response_ing['rxcuiStatusHistory']['derivedConcepts']['ingredientConcept'])\n",
    "            for i in range(0,num_ingredient):\n",
    "                ingredient = response_ing['rxcuiStatusHistory']['derivedConcepts']['ingredientConcept'][i]['ingredientRxcui']\n",
    "                ingr_list.append(ingredient)\n",
    "\n",
    "            ndc_rxcui_ingr_mapping[ndc] = ingr_list\n",
    "        else:\n",
    "            ndc_rxcui_ingr_mapping[ndc] = []\n",
    "    count += 1     \n",
    "    if count % 500 == 1:\n",
    "        print(count, flush=True)\n",
    "\n",
    "patient_prescriptions_rxcui_final_dict = {}\n",
    "patient_prescriptions_ingr_rxcui_final_dict = {}\n",
    "count = 0\n",
    "for key, item in patient_prescriptions_dict.items():\n",
    "    individual_rxcui_list = []\n",
    "    individual_ingr_list = []\n",
    "    for ndc_code in item:\n",
    "        if ndc_code in ndc_rxcui_mapping.keys():\n",
    "            individual_rxcui_list.append(ndc_rxcui_mapping[ndc_code])\n",
    "            individual_ingr_list.extend(ndc_rxcui_ingr_mapping[ndc_code])\n",
    "    \n",
    "    patient_prescriptions_rxcui_final_dict[key] = list(set(individual_rxcui_list))\n",
    "    patient_prescriptions_ingr_rxcui_final_dict[key] = list(set(individual_ingr_list))\n",
    "    count += 1\n",
    "    if count % 5000 == 1:\n",
    "        print(count, flush=True)\n",
    "        \n",
    "np.save('/data/chao/syn_mimic/preprocessing/patient_prescriptions_rxcui_final_dict.npy', patient_prescriptions_rxcui_final_dict)\n",
    "np.save('/data/chao/syn_mimic/preprocessing/patient_prescriptions_ingr_rxcui_final_dict.npy', patient_prescriptions_ingr_rxcui_final_dict)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac9e518",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ndc_rxcui_mapping))\n",
    "print(len(set(sum(list(ndc_rxcui_ingr_mapping.values()),[]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7577d03e",
   "metadata": {},
   "source": [
    "## 4. Other measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c75869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_bmi_bp_final_dict = np.load('/data/chao/syn_mimic/preprocessing/patient_bmi_bp_dict.npy', allow_pickle=True).item()\n",
    "patient_bmi_bp_final_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c6dcce",
   "metadata": {},
   "source": [
    "## 5. Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc19601",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_dict = np.load('/data/chao/syn_mimic/preprocessing/patients_dict_w_admission_n_die_inhosp.npy', allow_pickle=True).item()\n",
    "patients_final_dict = {}\n",
    "race_set = set()\n",
    "gender_set = set()\n",
    "for key, item in patients_dict.items():\n",
    "    race = item[5]\n",
    "    gender = item[0]\n",
    "    anchor_age = item[1]\n",
    "    anchor_year = item[2]\n",
    "    age_at_last_discharge = anchor_age + int(item[8][:4]) - anchor_year\n",
    "    if age_at_last_discharge > 91:\n",
    "        age_at_last_discharge = 91\n",
    "    patients_final_dict[key] = [age_at_last_discharge, gender, race]\n",
    "    race_set.add(item[5])\n",
    "    gender_set.add(item[0])\n",
    "    \n",
    "np.save('/data/chao/syn_mimic/preprocessing/patients_final_dict.npy', patients_final_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce52b46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_final_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f059a7e",
   "metadata": {},
   "source": [
    "## 6. Combine all info into a patient by concept matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09120019",
   "metadata": {},
   "outputs": [],
   "source": [
    "## figure out all columns\n",
    "# diagnoses\n",
    "patient_phecode_diagnosis_final_dict = np.load('/data/chao/syn_mimic/preprocessing/patient_phecode_diagnosis_final_dict.npy', allow_pickle=True).item()\n",
    "patient_phecode_space = {}\n",
    "for key, item in patient_phecode_diagnosis_final_dict.items():\n",
    "    for code in item:\n",
    "        if code not in patient_phecode_space.keys():\n",
    "            patient_phecode_space[code] = 0\n",
    "patient_phecode_space = OrderedDict(sorted(patient_phecode_space.items()))\n",
    "phecode_key_list = list(patient_phecode_space.keys())\n",
    "\n",
    "patient_diagnosis_section = {}\n",
    "for key, item in patient_phecode_diagnosis_final_dict.items():\n",
    "    individual_phecode_indicator = [0] * len(phecode_key_list)\n",
    "    for code in item:\n",
    "        individual_phecode_indicator[phecode_key_list.index(code)] = 1\n",
    "    patient_diagnosis_section[key] = individual_phecode_indicator\n",
    "    \n",
    "# procedures (not included in demo)\n",
    "patient_procedures_hcpcs_final_dict = np.load('/data/chao/syn_mimic/preprocessing/patient_procedures_hcpcs_dict.npy', allow_pickle=True).item()\n",
    "patient_cpt_space = {}\n",
    "for key, item in patient_procedures_hcpcs_final_dict.items():\n",
    "    for code in item:\n",
    "        if code not in patient_cpt_space.keys():\n",
    "            patient_cpt_space[code] = 0\n",
    "patient_cpt_space = OrderedDict(sorted(patient_cpt_space.items()))\n",
    "cpt_key_list = list(patient_cpt_space.keys())\n",
    "\n",
    "patient_procedure_section = {}\n",
    "for key, item in patient_procedures_hcpcs_final_dict.items():\n",
    "    individual_cpt_indicator = [0] * len(cpt_key_list)\n",
    "    for code in item:\n",
    "        individual_cpt_indicator[cpt_key_list.index(code)] = 1\n",
    "    patient_procedure_section[key] = individual_cpt_indicator\n",
    "    \n",
    "# medication (not included in demo)\n",
    "\n",
    "# other measures\n",
    "patient_bmi_bp_final_dict = np.load('/data/chao/syn_mimic/preprocessing/patient_bmi_bp_dict.npy', allow_pickle=True).item()\n",
    "patient_measure_section = copy.deepcopy(patient_bmi_bp_final_dict)\n",
    "\n",
    "# demographics\n",
    "patients_final_dict = np.load('/data/chao/syn_mimic/preprocessing/patients_final_dict.npy', allow_pickle=True).item()\n",
    "# merge race\n",
    "patient_demo_section = {}\n",
    "race_count = {'WHITE':0, 'BLACK':0, 'ASIAN':0, 'HISPANIC':0, 'UN':0, 'OTHER':0}\n",
    "for key, item in patients_final_dict.items():\n",
    "    if item[2].startswith('WHITE'):\n",
    "        race = [1,0,0,0,0,0]\n",
    "        race_count['WHITE'] = race_count['WHITE'] + 1\n",
    "    elif item[2].startswith('BLACK'):\n",
    "        race = [0,1,0,0,0,0]\n",
    "        race_count['BLACK'] = race_count['BLACK'] + 1\n",
    "    elif item[2].startswith('ASIAN'):\n",
    "        race = [0,0,1,0,0,0]\n",
    "        race_count['ASIAN'] = race_count['ASIAN'] + 1\n",
    "    elif item[2].startswith('HISPANIC'):\n",
    "        race = [0,0,0,1,0,0]\n",
    "        race_count['HISPANIC'] = race_count['HISPANIC'] + 1\n",
    "    elif item[2].startswith('UN'):\n",
    "        race = [0,0,0,0,1,0]\n",
    "        race_count['UN'] = race_count['UN'] + 1\n",
    "    else:\n",
    "        race = [0,0,0,0,0,1]\n",
    "        race_count['OTHER'] = race_count['OTHER'] + 1\n",
    "        \n",
    "    if item[1] == 'F':\n",
    "        gender = 1\n",
    "    else:\n",
    "        gender = 0\n",
    "        \n",
    "    patient_demo_section[key] = [item[0], gender] + race\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524e6c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_y_outcome = np.load('/data/chao/syn_mimic/preprocessing/one_y_outcome.npy', allow_pickle=True).item()\n",
    "\n",
    "patient_concept_mat = []\n",
    "for key, demo_vec in patient_demo_section.items():\n",
    "    if key in patient_diagnosis_section.keys():\n",
    "        diagnosis_vec = patient_diagnosis_section[key]\n",
    "    else:\n",
    "        diagnosis_vec = [0] * len(phecode_key_list)\n",
    "    if key in patient_measure_section.keys():\n",
    "        measure_vec = patient_measure_section[key]\n",
    "    else:\n",
    "        measure_vec = [np.nan] * 3\n",
    "    \n",
    "    patient_concept_mat.append([one_y_outcome[key]] + demo_vec + measure_vec + diagnosis_vec)\n",
    "    \n",
    "column_list = ['DIE_1y', 'AGE', 'GENDER'] + list(race_count.keys()) + ['BMI','DIASTOLIC','SYSTOLIC'] + phecode_key_list\n",
    "assert len(column_list) == len(patient_concept_mat[0])\n",
    "np.save('/data/chao/syn_mimic/preprocessing/column_list_only_diagnosis.npy', column_list)\n",
    "np.save('/data/chao/syn_mimic/preprocessing/patient_concept_mat_only_diagnosis.npy', patient_concept_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4902dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_concept_mat_df = pd.DataFrame(patient_concept_mat, columns = column_list)\n",
    "patient_concept_mat_df.to_csv('/data/chao/syn_mimic/preprocessing/patient_concept_mat_df.csv', index=False)\n",
    "patient_concept_mat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9edaf71",
   "metadata": {},
   "source": [
    "# Data summarization\n",
    "\n",
    "## Overall characteristics\n",
    "- **Number of patients**: 181,294\n",
    "- **Number of columns**: 1,600\n",
    "\n",
    "## Column breakdown\n",
    "- **Outcome (binary)**: Die in one year since last admission: 11.3%\n",
    "- **Age (continuous)**: 56.20 ± 20.39\n",
    "- **Gender (binary)**: Female vs Male: 53.3% vs 46.7%\n",
    "- **Race (onehot length 6)**: WHITE (67.3%)  BLACK (13.2%)  ASIAN (4.2%)  HISPANIC (5.5%)  UNKNOWN (4.2%)  OTHER (5.6%)\n",
    "- **BMI (continuous)**: 21.06 ± 277.03, max: 107840.2 (subject to outlier removal)  \n",
    "- **DIASTOLIC (continuous)**: 47.55 ± 36.42, max: 168.0\n",
    "- **SYSTOLIC (continuous)**: 81.87 ± 62.27, max: 243.0\n",
    "\n",
    "**Topic 10 prevalent phecodes:**\n",
    "- `401`: Hypertension (31.57%)\n",
    "- `272`: Disorders of lipoid metabolism (21.63%)\n",
    "- `285`: Other anemias (18.74%)\n",
    "- `401.1`: Essential hypertension (17.48%)\n",
    "- `272.1`: Hyperlipidemia (15.45%)\n",
    "- `530`: Diseases of esophagus (14.28%)\n",
    "- `427`: Cardiac dysrhythmias (13.95%)\n",
    "- `296`: Mood disorders (13.90%)\n",
    "- `318`: Tobacco use disorder (13.32%)\n",
    "- `276`: Disorders of fluid, electrolyte, and acid-base balance (13.18%)\n",
    "- `250`: Diabetes mellitus (13.12%)\n",
    "\n",
    "**Number of phecodes with less than x prevalence:**\n",
    "- 10<sup>-6</sup>: 0\n",
    "- 10<sup>-5</sup>: 25\n",
    "- 10<sup>-4</sup>: 224\n",
    "- 10<sup>-3</sup>: 718"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d3dc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "phecode_prevalence = {}\n",
    "for code in phecode_key_list:\n",
    "    phecode_prevalence[code] = np.mean(patient_concept_mat_df[code])\n",
    "\n",
    "phecode_prevalence = OrderedDict(sorted(phecode_prevalence.items(), key=itemgetter(1),reverse=True))\n",
    "phecode_prevalence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3a9c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.array(list(phecode_prevalence.values()))<0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91339ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(patient_concept_mat_df['BMI'])\n",
    "len(cpt_key_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432ff8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_ICD_diagnosis_final_dict = np.load('/data/chao/syn_mimic/preprocessing/patient_ICD_diagnosis_final_dict.npy', allow_pickle=True).item()\n",
    "patient_ICD_space = {}\n",
    "for key, item in patient_ICD_diagnosis_final_dict.items():\n",
    "    for code in item:\n",
    "        if code not in patient_ICD_space.keys():\n",
    "            patient_ICD_space[code] = 0\n",
    "patient_ICD_space = OrderedDict(sorted(patient_ICD_space.items()))\n",
    "ICD_key_list = list(patient_ICD_space.keys())\n",
    "\n",
    "# patient_diagnosis_section = {}\n",
    "# for key, item in patient_ICD_diagnosis_final_dict.items():\n",
    "#     individual_ICD_indicator = [0] * len(ICD_key_list)\n",
    "#     for code in item:\n",
    "#         individual_ICD_indicator[ICD_key_list.index(code)] = 1\n",
    "#     patient_diagnosis_section[key] = individual_ICD_indicator\n",
    "len(ICD_key_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d074a22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_concept_mat_df = pd.read_csv('/data/chao/syn_mimic/preprocessing/patient_concept_mat_df.csv')\n",
    "patient_concept_mat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b436cc33",
   "metadata": {},
   "source": [
    "# Data preprocessing for GAN training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36ebf59",
   "metadata": {},
   "source": [
    "## 1. Remove outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b562a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Focus on non-binary features, here we check the distribution characteristics of AGE, BMI, DIASTOLIC, and SYSTOLIC columns.\n",
    "cols = ['AGE', 'BMI', 'DIASTOLIC', 'SYSTOLIC']\n",
    "for col_name in cols:\n",
    "    col_data = list(patient_concept_mat_df[col_name])\n",
    "    print(col_name)\n",
    "    print('   min value: ', np.nanmin(col_data), ' max value: ', np.nanmax(col_data), ' mean value: ', np.nanmean(col_data), ' median value: ', np.nanmedian(col_data))\n",
    "\n",
    "for i in range(len(cols)):\n",
    "    plt.hist(list(patient_concept_mat_df[cols[i]]), density=True, bins=80)\n",
    "    plt.ylabel('Probability')\n",
    "    plt.xlabel(cols[i])\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff43f342",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Process outliers\n",
    "\n",
    "# AGE: looks normal except that there are ~7 thousand patients with age 91 because of the age procedure for privacy protection (age >=91 --> 91).\n",
    "\n",
    "# BMI: the max value is not reasonable --> correspond to an outlier. We remove patients with BMI > 60 or BMI < 10.\n",
    "print('Num of patients with BMI > 60: %d' % np.sum((patient_concept_mat_df['BMI']) > 60))\n",
    "print('Num of patients with BMI < 10: %d' % np.sum((patient_concept_mat_df['BMI']) < 10))\n",
    "patient_concept_mat_df.drop(patient_concept_mat_df[patient_concept_mat_df['BMI'] > 60].index, inplace = True)\n",
    "patient_concept_mat_df.drop(patient_concept_mat_df[patient_concept_mat_df['BMI'] < 10].index, inplace = True)\n",
    "\n",
    "# DIASTOLIC: the max value is reasonable but the min value isn't --> correspond to an outlier. We remove patients with Diastolic pressure > 30.\n",
    "print('Num of patients with DIASTOLIC pressure < 30: %d' % np.sum((patient_concept_mat_df['DIASTOLIC']) < 30))\n",
    "patient_concept_mat_df.drop(patient_concept_mat_df[patient_concept_mat_df['DIASTOLIC'] < 30].index, inplace = True)\n",
    "\n",
    "# SYSTOLIC: the min/max value is reasonable given the cohort was admitted to ICU/ED.\n",
    "\n",
    "patient_concept_mat_df = patient_concept_mat_df.reset_index(drop=True)\n",
    "\n",
    "# if DIASTOLIC > SYSTOLIC, remove the patient.\n",
    "dias_bp_list = list(patient_concept_mat_df['DIASTOLIC'])\n",
    "syst_bp_list = list(patient_concept_mat_df['DIASTOLIC'])\n",
    "remove_row_index_list = []\n",
    "for i in range(len(dias_bp_list)):\n",
    "    dias_bp = dias_bp_list[i]\n",
    "    syst_bp = syst_bp_list[i]\n",
    "    if dias_bp != dias_bp and syst_bp != syst_bp and dias_bp >= syst_bp:\n",
    "        remove_row_index_list.append(i)\n",
    "if len(remove_row_index_list) > 0:\n",
    "    patient_concept_mat_df.drop(remove_row_index_list, inplace = True)\n",
    "    print(\"%d patients with wrong BP relationship removed.\" % len(remove_row_index_list))\n",
    "else:\n",
    "    print(\"No BP violations.\")\n",
    "\n",
    "\n",
    "for i in range(len(cols)):\n",
    "    plt.hist(list(patient_concept_mat_df[cols[i]]), density=True, bins=80)\n",
    "    plt.ylabel('Probability')\n",
    "    plt.xlabel(cols[i])\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3137cfd",
   "metadata": {},
   "source": [
    "## 2. Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9307a2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Focus on non-binary features, here we check AGE, BMI, DIASTOLIC, and SYSTOLIC columns.\n",
    "# Check column-wise missing rate\n",
    "missing_ratio = {}\n",
    "for col_name in cols:\n",
    "    missing_ratio[col_name] = patient_concept_mat_df[col_name].isna().sum() / len(patient_concept_mat_df)   \n",
    "print(missing_ratio)\n",
    "\n",
    "# Determine missing value imputation strategy. \n",
    "# Since the missing rate for the three measures are high, one may choose to remove these columns.\n",
    "# In this demo, we apply a naive sampling strategy to impute missing data. One can also learn a ML model to predict the measures.\n",
    "cols = [col_name for col_name in cols if missing_ratio[col_name] > 0]\n",
    "random.seed(4)\n",
    "for col_name in cols:\n",
    "    missing_num = patient_concept_mat_df[col_name].isna().sum()\n",
    "    col_values = list(patient_concept_mat_df[col_name])\n",
    "    sampling_list = [x for x in col_values if np.isnan(x) == False]\n",
    "    for i in range(len(col_values)):\n",
    "        if np.isnan(col_values[i]) == True:\n",
    "            col_values[i] = random.choices(sampling_list)[0]\n",
    "\n",
    "    patient_concept_mat_df[col_name] = col_values\n",
    "    \n",
    "for i in range(len(cols)):\n",
    "    plt.hist(list(patient_concept_mat_df[cols[i]]), density=True, bins=80)\n",
    "    plt.ylabel('Probability')\n",
    "    plt.xlabel(cols[i])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b707f31",
   "metadata": {},
   "source": [
    "## 3. Normalize continuous columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b18d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize the continuous feature in to [0,1]\n",
    "# Store min max values for each related feature\n",
    "min_max_log = {}\n",
    "cols = ['AGE', 'BMI', 'DIASTOLIC', 'SYSTOLIC']\n",
    "for col_name in cols:\n",
    "    col_value = np.array(patient_concept_mat_df[col_name])\n",
    "    min_max_log[col_name] = [np.min(col_value), np.max(col_value)]\n",
    "    norm_col_value = (col_value - min_max_log[col_name][0]) / (min_max_log[col_name][1] - min_max_log[col_name][0])\n",
    "    patient_concept_mat_df[col_name] = list(norm_col_value)\n",
    "print(min_max_log)\n",
    "np.save('/data/chao/syn_mimic/preprocessing/min_max_log.npy', min_max_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd4f772",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_concept_mat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02ff85a",
   "metadata": {},
   "source": [
    "## 4. Remove extremely rare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fae83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove the binary columns with less than x 1s.\n",
    "cols = list(patient_concept_mat_df.columns)\n",
    "cols.remove('AGE')\n",
    "cols.remove('BMI')\n",
    "cols.remove('DIASTOLIC')\n",
    "cols.remove('SYSTOLIC')\n",
    "col_to_remove = []\n",
    "for col_name in cols:\n",
    "    col_value = np.array(patient_concept_mat_df[col_name])\n",
    "    if np.sum(col_value)/len(col_value) < 0.00005:\n",
    "        col_to_remove.append(col_name)\n",
    "for col_name in col_to_remove:\n",
    "    cols.remove(col_name)\n",
    "    \n",
    "cols = ['WHITE', 'BLACK', 'ASIAN', 'HISPANIC', 'UN', 'OTHER', 'DIE_1y', 'GENDER'] + cols[8:]\n",
    "\n",
    "patient_concept_mat_df_ = patient_concept_mat_df[cols + ['AGE','BMI','DIASTOLIC','SYSTOLIC']]\n",
    "patient_concept_mat_df_.to_csv('/data/chao/syn_mimic/preprocessing/preprocessed_training_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f5ea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_concept_mat_df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1bc74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(patient_concept_mat_df_['WHITE']))\n",
    "print(np.sum(patient_concept_mat_df_['BLACK']))\n",
    "print(np.sum(patient_concept_mat_df_['ASIAN']))\n",
    "print(np.sum(patient_concept_mat_df_['HISPANIC']))\n",
    "print(np.sum(patient_concept_mat_df_['UN']))\n",
    "print(np.sum(patient_concept_mat_df_['OTHER']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6668c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa69ee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = patient_concept_mat_df_.values\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(all_data)\n",
    "training_data = all_data[:int(len(all_data)*0.7)]\n",
    "testing_data = all_data[int(len(all_data)*0.7):]\n",
    "training_data_df = pd.DataFrame(data=training_data, columns=list(patient_concept_mat_df_.columns))\n",
    "testing_data_df = pd.DataFrame(data=testing_data, columns=list(patient_concept_mat_df_.columns))\n",
    "print(np.sum(training_data_df['DIE_1y'])/len(training_data_df))\n",
    "print(np.sum(testing_data_df['DIE_1y'])/len(testing_data_df))\n",
    "\n",
    "training_data_df.to_csv('/data/chao/syn_mimic/preprocessing/normalized_training_data.csv', index=False)\n",
    "testing_data_df.to_csv('/data/chao/syn_mimic/preprocessing/normalized_testing_data.csv', index=False)\n",
    "\n",
    "min_max_log = np.load('/data/chao/syn_mimic/preprocessing/min_max_log.npy', allow_pickle=True).item()\n",
    "for key, min_max in min_max_log.items():\n",
    "    min_, max_ = min_max[0], min_max[1]\n",
    "    col_values = np.array(training_data_df[key])\n",
    "    training_data_df[key] = (1 - col_values)*min_ + col_values*max_\n",
    "    col_values = np.array(testing_data_df[key])\n",
    "    testing_data_df[key] = (1 - col_values)*min_ + col_values*max_\n",
    "    \n",
    "training_data_df.to_csv('/data/chao/syn_mimic/preprocessing/original_training_data.csv', index=False)\n",
    "testing_data_df.to_csv('/data/chao/syn_mimic/preprocessing/original_testing_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456b727d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b8df3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc49bcef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
